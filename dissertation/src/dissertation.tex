% book example for classicthesis.sty
\documentclass[
  % Replace twoside with oneside if you are printing your thesis on a single side
  % of the paper, or for viewing on screen.
  oneside,
  %twoside,
  11pt, a4paper,
  footinclude=true,
  headinclude=true,
  cleardoublepage=empty
]{scrbook}

\usepackage{dissertation}
%---
\usepackage[T1]{fontenc}
\usepackage{textcomp}
\usepackage{algorithm2e}
% ===========
\usepackage[font=small,labelfont=bf,tableposition=top]{caption}
\usepackage[font=footnotesize]{subcaption}
\usepackage{algorithmic}
% ===========
\usepackage{colortbl}
\usepackage{tabularx}
\usepackage[most]{tcolorbox}
\usepackage{listings}
\usepackage{pgfplots}
% \usepackage[miktex]{gnuplottex}
\usepackage{tikz}
% \usepackage{gnuplot-lua-tikz}
% \usepackage{mathpazo}
\usepackage[acronym]{glossaries}
\pgfplotsset{width=10cm,compat=1.9}
% We will externalize the figures
\usepgfplotslibrary{external}
\tikzexternalize
%---
\usepackage[titles]{tocloft}
%% Aesthetic spacing redefines that look nicer to me than the defaults.
\setlength{\cftbeforechapskip}{2ex}
\setlength{\cftbeforesecskip}{0.5ex}
%% Use Helvetica-Narrow Bold for Chapter entries
\renewcommand{\cftpartfont}{%
  \fontsize{12}{14}\usefont{OT1}{phv}{bc}{n}\selectfont
}
\renewcommand{\cftchapfont}{%
  \fontsize{11}{13}\usefont{OT1}{phv}{bc}{n}\selectfont
}
\renewcommand{\cftsecfont}{%
  \fontsize{10}{11}\usefont{OT1}{phv}{}{n}\selectfont
}
\renewcommand{\cftsubsecfont}{%
  \fontsize{9}{10}\usefont{OT1}{phv}{}{n}\selectfont
}
\renewcommand{\cftfigfont}{%
  \fontsize{9}{10}\usefont{OT1}{phv}{}{n}\selectfont
}
\renewcommand{\cfttabfont}{%
  \fontsize{9}{10}\usefont{OT1}{phv}{}{n}\selectfont
}
%---

\definecolor{codegreen}{rgb}{0.4,0.4,0.4}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.5,0.4,0.8}
\definecolor{codehighlight}{rgb}{0.2,0.2,0.2} %{0.5,0.4,0.8}
\definecolor{backcolour}{rgb}{0.95,0.95,0.95}

\definecolor{s_orange}{HTML}{ef821c}
\definecolor{s_gray}{HTML}{8292A1}
\definecolor{s_line_gray}{HTML}{8e8f90}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{codehighlight}\textbf,
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    % numbers=left,                    
    % numbersep=1pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
\lstset{style=mystyle}
\captionsetup{font={footnotesize,sf,singlespacing}}

\newcommand{\eqname}[1]{\tag*{#1}}% Tag equation with name

\newcommand*{\source}[1]{%
    \textbf{Source:} \cite{#1}%
}

%usepackage[scaled=.92]{helvet}
\usepackage[all]{xy}
\usepackage{circuitikz}
% \usepackage[sorting=none,style=numeric]{biblatex}

% Title

\titleA{High Performance Fourier Transforms on GPUs}
% \titleB{Second line in title (if any)}
% \titleC{Third  line in title (if any)}

% Author

\author{Jorge Francisco Teixeira Bastos da Mota}

% Supervisor(es)

\supervisor{António Ramires}

% \cosupervisor{Co-supervisor (if any)}

% Date

\date{\myear} % change to text if date is not today

\makeglossaries  %  either use this ...

\makeindex	% ... or this

\begin{document}\fontfamily{phv}\fontseries{mc}\selectfont
    
% Add acronym definitions
\newacronym{gcd}{GCD}{Greatest Common Divisor}
\newacronym{lcm}{LCM}{Least Common Multiple}
    
% Cover page ---------------------------------------------
%	\thispagestyle{empty}
    \input{def/title}
%rm
    \cleardoublepage
%---------------------------------------------------------
    \pagenumbering{alph}
    \setcounter{page}{1}
%---------------------------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% NOTES:
% There are some commented chapters and sections to improve readability when writing the dissertation
% In the end some of those chapters could or could not be included in the final pre-dissertation submission

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \chapter*{Copyright and Terms of Use for Third Party Work}

% This dissertation reports on academic work that can be used by third parties as long as the internationally accepted standards and good practices are respected concerning copyright and related rights.
% \vskip 1em
% \noindent This work can thereafter be used under the terms established in the license below.
% \vskip 1em
% \noindent Readers needing authorization conditions not provided for in the indicated licensing should contact the author through the RepositóriUM of the University of Minho.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \section*{License granted to users of this work:}

% \CCBY % or replace by one in***************** the list below, cf https://alunos.uminho.pt/PT/estudantes/Formataes/3_Despacho_RT-31_2019_Anexo%203-Informa%c3%a7%c3%a3o-Direitor%20de%20Autor.docx 
%---------
%\CBYNCND
%\CCBYNCSA
%\CCBYNC
%\CCBYND
%\CCBYSA


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \chapter*{Acknowledgements}
% Write your acknowledgements here. Do not forget to mention the projects and grants that you have benefited from while doing your research, if any. Ask your supervisor about the specific textual format to use. (Funding agencies are quite strict about this.) 

% 	\cleardoublepage
    
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \chapter*{Statement of Integrity}

% I hereby declare having conducted this academic work with integrity.
% \vskip 1em\noindent
% I confirm that I have not used plagiarism or any form of undue use of information or falsification of results along the process leading to its elaboration. 
% \vskip 1em\noindent
% I further declare that I have fully acknowledged the Code of Ethical Conduct of the University of Minho.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter*{Abstract}

The continuous progress of the evolution of GPUs has increased the popularity of parallelizable algorithm implementations on this type of hardware.
Fast Fourier Transforms is a family of algorithms which are very useful for the computation of Discrete Fourier Transforms which is applied in many practical scenarios for serveral areas.

Due to its usefullness and the need to optimize Fast Fourier Transforms this algorithms are effectively computed on the GPU to take advantage of its parallelizable variants

In this dissertation we provide, compare and analyze FFT implementations with popular libraries that are known to compute this efficiently, and provide specially forged GLSL implementations in the context of applications.

\paragraph{Keywords} FFT, GLSL, cuFFT, analysis, performance.

    \cleardoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter*{Resumo}

O progresso contínuo da evolução dos GPUs aumentou a popularidade das implementações de algoritmos paralelizáveis neste tipo de hardware.
\textit{Fast Fourier Transforms} são uma família de algoritmos úteis para o cálculo de transformadas de Fourier discretas que são aplicadas em muitos cenários práticos para diversas áreas.

Devido à sua utilidade e à necessidade de otimizar as \textit{Fast Fourier Transforms}, esses algoritmos são efetivamente computados na GPU para aproveitar suas variantes paralelizáveis

Nesta dissertação, fornecemos, comparamos e analisamos implementações de FFT com bibliotecas populares que são conhecidas por computar isso de forma eficiente e fornecemos implementações GLSL especialmente forjadas no contexto de aplicativos.
    
\paragraph{Palavras-chave} FFT, GLSL, cuFFT, análise, performance


    \cleardoublepage
    
    \pagenumbering{roman}
    \setcounter{page}{3}
    %pagestyle{fancy}   % -------- removed
    
    % Document
    \cleardoublepage
    \phantomsection
    % Adds 'Contents' to Contents chapter
    % \addcontentsline{toc}{chapter}{Contents}
    \tableofcontents
    
    \cleardoublepage
    \listoffigures
    
    \cleardoublepage
    \listoftables
    
    % \cleardoublepage
    % \lstlistoflistings

    % \printglossary[type=\acronymtype]
    
    % Add list of acronyms
    \cleardoublepage
    \pagenumbering{arabic}
    \setcounter{page}{5}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                         Introduction                         %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction} \label{chap:introduction}

\section{Contextualization} \label{sec:contextualization}

% % 1.1 O que sao transofrmadas de fourier e em que contexto se enquadram
The Fast Fourier Transforms have been present in our sorroundings for a long time, they're used extensively in digital signal processing including many other areas and they often need to be used in a realtime context, where the computations must be performed fast enough. Fast Fourier Transforms essentially are optimized algorithms to compute the Discrete Fourier Transform of some data, data that might be sampled from a signal, an oscilating object or even an image, which is transformed into the frequency domain allowing any kind of processing for a relativelly low computational cost. Despite already existing pretty fast computations of the FFT, many applications require the processing of serveral transforms so its necessary to manage the implementations properties and achieve the best speed.

% 2. De que forma este algoritmo pode beneficiar ao ser usado no GPU eao ser usado para aplicações  

\section{Motivation} \label{sec:motivation}

The continuous progress of the evolution of GPUs has increased the popularity of parallelizable algorithm implementations on this type of hardware.
% % UNUSED: \cite{zhang2013design}
Notably the FFT algorithms family is constantly present in Computer Graphics, it's usual to find inlined implementations in shader code which offer reliable Fast Fourier Transforms \cite{flugge2017realtime}, but lack tuning of settings for a more optimized versions of these computations. On the other hand there's already out there libraries that provide efficient implementations of FFT on the GPU and CPU like cuFFT \cite{nvidiacufft}, a library provided by NVIDIA exclusively for their GPU's implemented for CUDA, and FFTW \cite{frigo2012fftw}, a library dedicated to computations of FFT on the CPU with SIMD instructions support.

% FIXME: THIS PARAGRAPH IS NOT OK THE PROBLEM ISNT SYNCRONIZATION IN THE GRAPHICS PIPELINE
Although this libraries can provide efficient transforms with specialized cases over a proper plan, in some applications its performance might be compromised for cases where, for example, the graphics pipeline needs to be sincronized with the computation of the Fourier Transform.

\section{Objectives} \label{sec:objectives}

The main objective of this dissertation is to provide efficient FFT alternatives in GLSL compared with dedicated tools for high performance of FFT computations like NVIDIA cuFFT library or FFTW, while analysing the intrinsic of a good Fast Fourier Transform implementation on the GPU and even make a one to one comparison of implementations on different frameworks. % ie: if the same implementation has different costs in different frameworks (cuda, opencl, compute shaders in glsl)
To accomplish the main objective there are two stages taken in consideration, \textit{Analysis of CUDA and GLSL kernels} to be well settled in their differences and to have a reference for the second stage \textit{Analysis of application specific implementations} which will cluster the study's main objective and where we'll use as case of study applications with implementation of the FFT in the field of Computer Graphics that require realtime performance.

% ====== New Planning Schedule

With constant progression of the research needed for this project, some steps of the work plan were refactored to meet the needs. The two main stages of the objectives stay the same but there are some adjustments to the schedule dates and steps as shown in \autoref{tab:schedule}.

\begin{itemize}
    \item \textbf{Research Fast Fourier Transform}
    \item \textbf{Study cuFFT}, understand internal optimizations and prepare specialized profiles.
    \item \textbf{Analysis of CUDA and GLSL kernels} for FFT raw computations.
    \item \textbf{Research of Application driven FFT}, specialized implementations on the context of the application.
    % \item \textbf{Benchmarking} and comparison of work performed.
    \item \textbf{Writing of pre-dissertation}
    \item \textbf{Writing of dissertation}
\end{itemize}


\begin{table}[ht]
    % \label{tab:planning}
    \centering
    \scriptsize
    \sffamily
    \renewcommand{\arraystretch}{1.5}%
    \begin{tabularx}{50em}{| c | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y |} 
        \cline{1-12}
        & \multicolumn{3}{c|}{2021} & \multicolumn{8}{c|}{2022} \\
        \cline{2-12}
        & Nov & Dez & Jan & Feb & Mar & Apr & May & Jun & Jul & Aug & Set\\
         \cline{1-12}

         Research Fast Fourier Transform & \multicolumn{3}{c|}{\cellcolor[gray]{0.8}} & & & & & & & & \\
        \cline{1-12}
        
        Study cuFFT & & & & \multicolumn{1}{c|}{\cellcolor[gray]{0.5}} & & & & & & & \\
        \cline{1-12}
        
        Analysis of CUDA and GLSL kernels & & & & \multicolumn{3}{c|}{\cellcolor[gray]{0.5}} & & & & & \\
        \cline{1-12}
        
        Research of Application driven FFT & & & & & & & \multicolumn{3}{c|}{\cellcolor[gray]{0.5}} & & \\
        \cline{1-12}
        
        % Benchmarking & & & & & & \multicolumn{1}{c|}{\cellcolor[gray]{0.5}} & & & \multicolumn{1}{c|}{\cellcolor[gray]{0.5}} & & \\
        % \cline{1-12}
        
        Writing of pre-dissertation & \multicolumn{3}{c|}{\cellcolor[gray]{0.8}} & & & & & & & & \\
        \cline{1-12}
        
        Writing of dissertation & & & \multicolumn{1}{c|}{\cellcolor[gray]{0.8}} &\multicolumn{8}{c|}{\cellcolor[gray]{0.5}} \\
        \cline{1-12}
    \end{tabularx}
    \caption{Dissertation schedule}
    \label{tab:schedule}
\end{table}

\section{Document Organization} \label{sec:document-organization}

% chap 1
This dissertation is organized in 3 chapters. Firstly, the \autoref{chap:introduction} exposes an introduction to the subject of this dissertation with the respective background information and defines objectives including contextualization and this document organization section.

% chap 2
To give a state of the art overview of the theory and practice associated with Fourier Transforms, \autoref{chap:state-of-the-art} covers most of basic understandings and algorithms needed for later chapters, this will only take simple approachs to each concept to give intuitive insight and empirical explanations without proving it formally.

% chap 3 % TODO: When chapter 3 label is available, autoref it in the paragraph
% Following the state of the art, chapter 3 will build a in depth analysis of FFT computation comparisons having several conditions in mind and comparing tradeoffs in different implementations, since this chapter will in only focus on raw FFT computations most of the application driven alternatives will be pushed to the next chapter

% chap 4 % TODO: When chapter 4 label is available, autoref it in the paragraph
% Finally, to culminate the past chapters, the chapter 4 is going to provide application driven implementations with performance-wise approaches, with a real application scenario were its performance is critical.

%TODO: Finish this

% A reaader with a good understanding of how the FFT works can skip to chapter <chaper_name>

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                       State of the Art                       %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{State of the Art} \label{chap:state-of-the-art}

\section{Fourier Transform} \label{sec:fourier-transform}

\subsection{What is Fourier Transform} \label{subsec:what-is-fourier-transform}

The \textbf{Fourier Transform} is a mathematical method to transform the domain refered to as \textit{time} of a function, to the \textit{frequency} domain, intuitively the Inverse Fourier Transform is the corresponding method to reverse that process and reconstruct the original function from the one in \textit{frequency} domain representation.

Although there are many forms, the Fourier Transform key definition can be described as:

% Forward Fourier Transform
%FIXME: This equations are replacing the reference number for the name with '\eqname'
% It must show the name AND the number
\begin{equation} \label{eq1}
    % \begin{split}
    X(f) = \int_{-\infty}^{+\infty} x(t)e^{-i f t} dt \\ %\eqname{Forward Fourier Transform} \\
    % \end{split}
\end{equation}

% Invense Fourier Transform
%FIXME: This equations are replacing the reference number for the name with '\eqname'
% It must show the name AND the number
\begin{equation} \label{eq2}
        x(t) = \frac{1}{2\pi} \int_{-\infty}^{+\infty} X(f)e^{-i f t} df \\ %\eqname{Inverse Fourier Transform} \\
\end{equation}

% REVIEW
% FIXME: I think f isn't REAL, its COMPLEX
\begin{itemize}
    \item \( x(t), \forall t \in \mathbb{R} \rightarrow \) function in \textit{time} domain representation with real \( t \).
    \item \( X(f), \forall f \in \mathbb{R} \rightarrow \) function in \textit{frequency} domain representation with real \( f \), also called the Fourier Transform of \( x(t) \)
    \item \( i \rightarrow \) imaginary unit \( i = \sqrt{-1} \)
\end{itemize}

This formulation shows the usage of complex-valued domain since the imaginary unit \( i \) doesn't represent a value in the set of real numbers, making the fourier transform range from real to complex values, one complex coefficient per frequency \( X : \mathbb{R} \rightarrow \mathbb{C} \) 

If we take into account the Euler's formula, we can replace the Fourier Transform for an equivalent, fragmenting the euler constant for a sine and cosine pair.

% Euler's Formula
\begin{equation} \label{eq:euler}
    e^{ix} = \cos x + i \sin x \\ %\eqname{Euler's Formula} \\
\end{equation}

% Forward Fourier Transform with Euler's Formula
\begin{equation}
    X(f) = \int_{-\infty}^{+\infty} x(t) (\cos (-f t) + i \sin (-f t)) dt \\
\end{equation}

Hence, we can break the Fourier Transform apart into two formulas that give each coefficient of the sine and cosine components as functions without dealing with complex numbers.

% Forward Fourier Transform sine and consine
\begin{equation}
    \begin{split}
        X_{a}(f) = \int_{-\infty}^{+\infty} x(t) \cos (f t) dt \\
        X_{b}(f) = \int_{-\infty}^{+\infty} x(t) \sin (f t) dt \\
    \end{split}
\end{equation}


% FIXME: This might also be applied to the Inverse, study this later and try to deduce the correspondant pair of formulas
% NOTE: This is important for future reference

% Fourier's original formulation of the transform did not use complex numbers, but rather sines and cosines. % Chatfield, Chris (2004), The Analysis of Time Series: An Introduction, Texts in Statistical Science (6th ed.), London: Chapman & Hall/CRC, ISBN 9780203491683.

% TODO: explain the formula better
The above definition of the Fourier Integral \autoref{eq1} can only be valid if the integral exists for every value of the parameter \(f\). This model of the fourier transform applied to infinite domain functions is called \textbf{Continous Fourier Transform} and its targeted to the calculation of the this transform directly to functions with only finite discontinuities in \( x(t) \).

\subsection{Where it is used} \label{subsec:where-it-is-used}

It's noticieable the presence of Fourier Transforms in a great variety of apparent unrelated fields of application, even the FFT is often called ubiquitous\footnote{present, appearing, or found everywhere.} due to its effective nature of solving a great hand of problems for the most intended complexity time. Some of the fields of application include Applied Mechanics, Signal Processing, Sonics and Acoustics, Biomedical Engineering, Instrumentation, Radar, Numerical Methods, Electromagnetics, Computer Graphics and more \cite{brigham1988fast}. % \gls{gcd}

One of the most well known cases of application is \textbf{Signal Analysis}, the Fourier Transform is probably the most important tool for analyzing signals, when representing a signal with amplitude as function of time, a signal can be translated to the frequency domain, a domain that consists of signals of sines and consines waves of varied frequencies, as demonstrated in \ref{fig:signal-decomposition}, but to calculate the coefficients of those waves we need to use the Fourier Transform.

\begin{figure}[h] 
    \centering
    \includegraphics[width=0.5\textwidth]{imgs/fft_time_freq.png}
    \caption{Time to frequency signal decomposition \source{fftntiaudio}}
    \label{fig:signal-decomposition}
\end{figure}

% REVIEW
Since the sine and consine waves are in simple waveforms they can then be manipulated with relative ease. This process is constantly present in communications since the transmission of data over wires and radio circuits through signals and most devices nowadays perform it frequently


% TODO:
% - Elaborate more
% - Maybe describe the polynomial multiplication too
% - Maybe move the 'jia2014polynomial' citation
% . . .

And much more applications such as polynomial multiplication \cite{jia2014polynomial}, numerical integration, time-domain interpolation, x-ray diffracition ...

% \begin{tikzpicture}
%   \begin{axis}[
%       axis lines = left,
%       xlabel = \(x\),
%       ylabel = {\(f(x)\)},
%   ]
%   %Below the red parabola is defined
%   \addplot [
%       domain=-10:10, 
%       samples=100, 
%       color=red,
%   ]
%   {x^2 - 2*x - 1};
%   \addlegendentry{\(x^2 - 2x - 1\)}
%   %Here the blue parabola is defined
%   \addplot [
%       domain=-10:10, 
%       samples=100, 
%       color=blue,
%       ]
%       {x^2 + 2*x + 1};
%   \addlegendentry{\(x^2 + 2x + 1\)}
  
%   \end{axis}
%   \end{tikzpicture}
% Dar 2 exemplos principais de como é aplicado e uma breve explicação
% - Signal processing

% Denote in the end that we'll use a different case of application for this comparison (might not be true since we could use the image processing case as study)


\section{Discrete Fourier Transform} \label{sec:discrete-fourier-transform}
% \section{Discrete Fourier Transform}

The Fourier Transform of a finite sequence of equally-spaced samples of a function is the called the \textbf{Discrete Fourier Transform} (DFT), it converts a finite set of values in \textit{time} domain to \textit{frequency} domain representation. Its the most important type of transform since it deals with a discrete amount of data and has the popular algorithm in which is the center of attention of fourier transforms, which can be implemented in machines and be computed by specialized hardware.

% Forward Discrete Fourier Transform
%FIXME: This equations are replacing the reference number for the name with '\eqname'
% It must show the name AND the number
\begin{equation} \label{eq3}
    X_{k} = \sum_{n=0}^{N-1}x_{n} \cdot e^{- \frac{i 2 \pi}{N}kn} \\ %\eqname{Forward Discrete Fourier Transform} \\
\end{equation}

% Inverse Discrete Fourier Transform
%FIXME: This equations are replacing the reference number for the name with '\eqname'
% It must show the name AND the number
\begin{equation} \label{eq4}
    x_{n} = \frac{1}{N} \sum_{k=0}^{N-1}X_{k} \cdot e^{\frac{i 2 \pi}{N}kn} \\ %\eqname{Inverse Discrete Fourier Transform} \\
\end{equation}

% REVIEW (english)
Notably, the discrete version of the Fourier Transform has some obvious differences since it deals with a discrete time sequence, the first difference is that the sum covers all elements of the input values instead of integrating the infinite domain of the function, but we can also notice that the exponential, similar to the aforesaid, divides the values by \(N\) (\(N\) being the total number of elements in the sequence) due to the inability to look at frequency and time \(ft\) continuously we instead take the \(k\)'th frequency over \(n\).

We can have a more simplified expansion of this formula with:

\begin{equation*}
    X_{k} = x_{0} + x_{1}e^{\frac{i 2 \pi}{N}k} + ... + x_{N-1}e^{\frac{i 2 \pi}{N}k(N-1)} \\
\end{equation*}

% FIXME: Maybe the word i want isn't simplified because the equation is getting longer
Having this sum simplified we then only need to resolve the complex exponential, and we can do that by replacing the \(e^{\frac{i 2 \pi}{N}kn}\) by the euler formula as mentioned before to reduce the maths to a simple sum of real and imaginary numbers.

% REVIEW (math)
\begin{equation} \label{dft_reduction}
    X_{k} = x_{0} + x_{1} (\cos{b_{1}} + i\sin{b_{1}}) + ... + x_{N-1} (\cos{b_{N-1}} + i\sin{b_{N-1}}) \\
\end{equation}

\begin{equation*}
    \text{where } \\ b_{n} = \frac{ 2 \pi}{N}kn \\
\end{equation*}


Finally we'll be left with the result as a complex number

\begin{equation*}
    X_{k} = A_{k} + i B_{k}
\end{equation*}

% 1. Explicar como funciona a aplicação da DFT a uma sequência (fazer um exemplo para sinais visto que vamos ter que mencionar a frequencia de nyquist)

\paragraph{Example} \label{example1} Let us now follow an example of calculation of the DFT for a sequence \(x\) with N number of elements.

\pagestyle{empty}
% Plot the cosine wave graph with the sample values
% \begin{figure*}
%     \begin{tikzpicture}
%         \begin{axis}[width=9cm,height=4cm,
%             axis lines = center,
%             axis on top,
%             axis line style={thick},
%             ticklabel style={fill=white,font=\scriptsize, inner sep=1pt},
%             xmin=0, xmax=360,
%             ymin=-1.9, ymax=1.9,
%             % ytick={-2,-1,...,2},
%             % xtick={-2,-1,...,2},
%             legend style={draw=none,fill=white, fill opacity=0.75, 
%                           font=\scriptsize, text opacity=1, inner sep=1pt,
%                           anchor=north east, at={(1,1)}, legend columns=-1},
%             domain=0:360,
%             samples=181,
%             no marks
%                     ]
%         \addplot +[s_orange,thick] {cos(x)};
%         \legend{$\cos(x)$}
%         \end{axis}
%     \end{tikzpicture}
% \end{figure*}

\begin{equation*}
    x = 
    \begin{bmatrix}
        1 & 0.707 & 0 & -0.707 & -1 & -0.707 & 0 & 0.707\\
    \end{bmatrix}
\end{equation*}
\begin{equation*}
    N = 8
\end{equation*}

% REVIEW: Not sure about this phrase
With this sequence we now want to transform it into the frequency domain, and for that we need to apply the Discrete Fourier Transform to each element \( x_{n} \rightarrow X_{k} \), thus, for each \(k\)'th element of \(X\) we apply the DFT for every element of \(x\).

% REVIEW: Not sure if i should put intermediate steps in this apply of the DFT
\begin{equation*}
    X_{0} = 1 \cdot e^{- \frac{i 2 \pi}{8} \cdot 0 \cdot 0} \\
        + 0.707 \cdot e^{- \frac{i 2 \pi}{8} \cdot 0 \cdot 1}  \\
        + ...  \\
        + 0.707 \cdot e^{- \frac{i 2 \pi}{8} \cdot 0 \cdot 7} \\
\end{equation*}
\begin{equation*}
    = (0 + 0i)
\end{equation*}
\begin{equation*}
    X_{1} = 1 \cdot e^{- \frac{i 2 \pi}{8} \cdot 1 \cdot 0} \\
        + 0.707 \cdot e^{- \frac{i 2 \pi}{8} \cdot 1 \cdot 1}  \\
        + ...  \\
        + 0.707 \cdot e^{- \frac{i 2 \pi}{8} \cdot 1 \cdot 7} \\
\end{equation*}
\begin{equation*}
    = (4 + 0i)
\end{equation*}

\begin{equation*}
    . . .
\end{equation*}

\begin{equation*}
    X_{7} = 1 \cdot e^{- \frac{i 2 \pi}{8} \cdot 7 \cdot 0} \\
        + 0.707 \cdot e^{- \frac{i 2 \pi}{8} \cdot 7 \cdot 1}  \\
        + ...  \\
        + 0.707 \cdot e^{- \frac{i 2 \pi}{8} \cdot 7 \cdot 7} \\
\end{equation*}
\begin{equation*}
    = (4 + 0i)
\end{equation*}

% TODO: Should i do this ^ for the idft too?

And that will produce our complex-valued output in frequency domain, as simple as that.
\begin{equation*}
    X = 
    \begin{bmatrix}
        0i & 4+0i & 0i & 0i & 0i & 0i & 0i & 4+0i\\
    \end{bmatrix}
\end{equation*}


% TODO:
% [-] 1. Justify why the hz 1 isn't with just 1 since the input sequence comes from a sampled cosine wave and mention the nyquist limit (Not sure if i want to add this)
%   [-] 1.1. Talk about the properties of the magnitude and phase 
% [x] 2. Perform this calculation as a matrix dot product and that makes it better for the computer to compute
%   [1/2] 2.1 Continue previous example but now with matrix multiplication form
% [ ] 3. Algorithmic preview of the dft
% [x] 4. Last phrase that introduces the next chapter FFT

% NOTE: 2.
\subsection{Matrix multiplication} \label{subsec:matrix-multiplication}
The example shown above is done sequentially as if each frequency pin is computed individually, but there's a way to calculate the same result by using matrix multiplication \cite{rao2018transform}. Since the operations are done equally without any extra step we can group all analysing function sinusoids (\(e^{- \frac{i 2 \pi}{N} k n}\)), also refered to as twiddle factors.

% \ref{example1}

\begin{equation*}
    W = 
    \begin{bmatrix}
        \omega_{N}^{0 \cdot 0}     & \omega_{N}^{1 \cdot 0}     & \dots  & \omega_{N}^{(N-1) \cdot 0}     \\
        \omega_{N}^{0 \cdot 1}     & \omega_{N}^{1 \cdot 1}     & \dots  & \omega_{N}^{(N-1) \cdot 1}     \\
        \vdots                     & \vdots                     & \ddots & \vdots                          \\
        \omega_{N}^{0 \cdot (N-1)} & \omega_{N}^{1 \cdot (N-1)} & \dots  & \omega_{N}^{(N-1) \cdot (N-1)} \\
    \end{bmatrix} =
    \begin{bmatrix}
        1      & 1              & \dots  & 1                          \\
        1      & \omega         & \dots  & \omega^{(N-1)}             \\
        \vdots & \vdots         & \ddots & \vdots                     \\
        1      & \omega^{(N-1)} & \dots  & \omega^{(N-1) \cdot (N-1)} \\
    \end{bmatrix}
\end{equation*}
\begin{equation*}
    \text{where } \omega_{N} = e^{- \frac{i 2 \pi}{N}}
\end{equation*}

% FIXME: I dont like the way this two phrases are right now, change later
The substitution variable \(\omega\) allows us to avoid writing extensive exponents.

The symbol \(W\) represents the transformation matrix of the Discrete Fourier Transform, also called DFT matrix, and its inverse can be defined as.

\begin{equation*}
    W^{-1} = \frac{1}{N} \cdot
    \begin{bmatrix}
        1      & 1                  & \dots  & 1                              \\
        1      & \omega_{N}         & \dots  & \omega_{N}^{(N-1)}             \\
        \vdots & \vdots             & \ddots & \vdots                         \\
        1      & \omega_{N}^{(N-1)} & \dots  & \omega_{N}^{(N-1) \cdot (N-1)} \\
    \end{bmatrix}
\end{equation*}

\begin{equation*}
    \text{where } \omega_{N} = e^{- \frac{i 2 \pi}{N}} \\
\end{equation*}

By using this matrix multiplication form we can have a more efficient way to compute the DFT in hardware.  

\begin{equation*}
    X = W \cdot x \\ %\eqname{Matrix DFT} \\
\end{equation*}
\begin{equation*}
    x = W^{-1} \cdot X \\ %\eqname{Matrix IDFT} \\
\end{equation*}

Moreover we might also want to normalize the matrix by \( \sqrt{N} \) for both Matrix DFT and IDFT instead of just normalizing the IDFT by \(N\), that will make \(W\) a unitary matrix \cite{horn2012matrix}.
The advantage of using a unitary matrix is that we only need to reasign the constant substution variable \(\omega_{N}\) to be able to invert the dft, the matrix multiplication stays the same for both DFT and IDFT. 
% FIXME: This phrase isn't good in this context, is contradicting the aforesaid.
Nevertheless later we will verify that the use of sqrt function isn't desirable for the implementation of any dft.

% NOTE: 2.1.
\paragraph{Example} \label{example1.2} Continuing the example \ref{example1}, we can adapt the aplication of the DFT to the matrix multiplication form.

\begin{equation*}
    W =
    \begin{bmatrix}
        1      & 1              & \dots  & 1               \\
        1      & \omega_{8}     & \dots  & \omega_{8}^{7}  \\
        \vdots & \vdots         & \ddots & \vdots          \\
        1      & \omega_{8}^{7} & \dots  & \omega_{8}^{49} \\
    \end{bmatrix}
\end{equation*}
\begin{equation*}
    \text{where } \omega_{8} = e^{\frac{i 2 \pi}{8}}
\end{equation*}

\begin{equation*}
    X = W \cdot x = W \cdot 
    \begin{bmatrix}
        1      \\
        0.707  \\
        \vdots \\
        0.707  \\
    \end{bmatrix} =
    \begin{bmatrix}
        0      \\
        4+0i  \\
        \vdots \\
        4+0i  \\
    \end{bmatrix}
\end{equation*}


% NOTE: 3. Algorithmic preview of the dft
\hfill \break
% NOTE: 4. Last phrase that introduces the next chapter FFT
% REVIEW: (english) Usage of word conspicuous
It's conspicuous that the complexity time for each multiplication of every singular term of the sequence with the complex exponential value is \(O(N^{2})\), hence, the computation of the Discrete Fourier Transform rises exponentially as we use longer sequences. Therefore, over time new algorithms and techniques where developed to increase the performance of this transform due to its usefulness. 


\section{Fast Fourier Transform} \label{sec:fast-fourier-transform}

The Fast Fourier Transform (FFT) is a family of algorithms that effectively compute the Discrete Fourier Transform (DFT) of a sequence and its inverse. These algorihtms essentially compute the the same result as the DFT but the direct usage of the DFT formulation is too slow for its applications. Thus, FFT algorithms exploit the DFT matrix structure by employing a divide-and-conquer approach \cite{chu1999inside} to segment its application.

Over time serveral variations of the algorithms were developed to improve the performance of the DFT and many aspects were rethought in the way we apply and produce the resulting transform, in this section we'll cover at some of those variations. % and utilities. % FIXME: Here 'utilities' doesn't fit quite right but i cant find the word i want. 

% NOTE: There's a newline here since the first block of text is introducing the FFT concept, and the next paragraph is about the algorithms and what well talk about next.

% TODO:
% 1.1 Mention some of the algorithms and authors names
% 1.2 'The one well discuss now is Radix-2' and here talk about how this two main algorithms work and why its only for power of 2 cases
% Algorithms
% 2.1

% 1.1
\paragraph{}
There are many algorithms and aproaches on the FFT family such as the well known Cooley-Tukey, known for its simplicity and effectiveness to compute any sequence with size as a power of two, but also Rader's algorithm \cite{rader1968discrete} and Bluestein's algorithm \cite{bluestein1970linear} which both deal prime sized sequences, and even the Split-radix FFT \cite{yavne1968economical} that recursively expresses a DFT of length \(N\) in terms of one smaller DFT of length \(N/2\) and two smaller DFTs of length \(N/4\). 
% FIXME: 'that recursively expresses a DFT of length N in terms of one smaller DFT of length N/2 and two smaller DFTs of length N/4.' this is cited directly from https://en.wikipedia.org/wiki/Split-radix_FFT_algorithm try to rewrite later from a good source

% 1.2
The next two sections focus on the Cooley–Tukey algorithm, most specifically the radix-2 decimation-in-time (DIT) FFT and radix-2 decimation-in-frequency (DIF) FFT, which requires the input sequence to have a power of two size.

% Describe here everything that the DIT and DIF have in common

\subsection{Radix-2 Decimation-in-Time FFT} \label{subsec:radix-2-decimation-in-time-fft}

% 1. Explain the objective and what the DIT term means in the applied algorithm
% (is one of the most used)

The Radix-2 Decimation-in-Time FFT algorithm rearranges the original Discrete Fourier Transform (DFT) formula into two subtransforms, one as a sum over the even indexed elements and other as a sum over the odd indexed elements. The \autoref{eq:dit} describes this procedure with already simplified math, and hints the recursive decomposition of the DFT of size \(N/2\).

\begin{equation} \label{eq:dit}
    X_{k} = \sum_{n=0}^{\frac{N}{2}-1}x_{2n} \cdot \omega_{N/2}^{k(2n)} + \omega_{N}^{k} \sum_{n=0}^{\frac{N}{2}-1}x_{2n+1} \cdot \omega_{N/2}^{k(2n+1)} \\
\end{equation}

\begin{equation*}
    \text{where } \omega_{N} = e^{\frac{i 2 \pi}{N}}
\end{equation*}

This formulation successfully segments the full sized DFT into two \(N/2\) sized DFT's of the even and odd indexed elements where the later is multiplied by a twiddle factor \( \omega_{N}^{k} \). 
% \( X_{N} = E_{N/2} + W * O_{N/2} \)

This algorithm is a Radix-2 Decimation-in-Time in the sence that the time values are regrouped in 2 subtransforms, and the decomposition reduces the time values to the frequency domain. Since the understanding of this algorithm can be aplied recursively, the \autoref{fig:dit-fft} illustrates the basic behaviour and represents the \(N/2\) subtransforms with boxes that can be filled by the recursive application of this algorithm to produce the frequency domain sequence.


% TODO: Cite this somewhere in these two topics
% \cite{jones2014digital}

\begin{figure}[h] 
    \centering
    \includegraphics[width=0.5\textwidth]{imgs/dit_fft.png}
    \caption{Radix-2 Decimation-in-Time FFT \source{jones2014digital}}
    \label{fig:dit-fft}
\end{figure}

% 2. Continue explaining this algorithm

Effectively, this smaller DFT's are recursively reduced by this algorithm until theres only the computation of a length-2 DFT where its only applied the Cooley-Tukey butterfly operation \cite{chu1999inside} illustrated in \autoref{fig:dit-butterfly}.

% NOTE: Handmade since there wan't one that had exacly what i wanted
\begin{figure}[h] 
    \centering
    \includegraphics[width=0.5\textwidth]{imgs/dit_butterfly.png}
    \caption{Cooley-Tukey butterfly}
    \label{fig:dit-butterfly}
\end{figure}

% "Whereas direct computation of all N DFT frequencies according to the DFT equation would require N2 complex multiplies and N2−N complex additions (for complex-valued data), by reusing the results of the two short-length DFTs as illustrated in Figure, the computational cost is now" 

The complexity work within the algorithm is distributed with the DIT approach which decomposes each DFT by 2 having \(\log{N}\) stages \cite{smith2007mathematics} while there are approximately \(N\) complex multiplications needed for each stage of the DIT decomposition, therefore the multiplication complexity for a \(N\) sized DFT is reduced from \(O(N^{2})\) to \(O(N \log{N})\) without any programming specific optimisations.

Additionally, this algorithm and the one in \autoref{subsec:radix-2-dif} both contain a bit reversal step but used in different ways. For the DIT FFT  the input sequence of the algorithm must be in bit reversal order since the algorithm returns a natural order sequence but requires the input to be bit reversed. This way we need to apply the bit reversal at the beginning before applying the algorithm.

However it seems shadowed in \autoref{alg:dit} the implementation of the bit reversal is quite simple and any decent version can be used in regards of this algorithm. The key idea is that each element must be placed in its bit reversed index, so for each element of the sequence the $bit\_reverse$ version of the index is calculated and the element is swapped with the on in the original index.

The $bit\_reverse$ of an index depends directly on the indexing domain of the input sequence, therefore it needs the size $N$, or more precisely the $\log{N}$ value, to use as a reference to reverse the bit order while maintaining the value within the sequence range.

% FIXME: Nor sure if this format is clear and easy to understand
\paragraph{EXAMPLE} For an index value of $4$ and a size $N$ of $256$, the bit reverse is described in \autoref{eq:example-bit-reverse}. \newline

\begin{equation} \label{eq:example-bit-reverse}
    \begin{aligned}
        \log{N} = 8 \\
        4 = 0b00000100, representation in 8 bits  \\
        bit_reverse(0b00000100) = 0b00100000 \\
        0b00100000 = 32 \\
    \end{aligned}
\end{equation}

In practice, \autoref{alg:dit} demonstrates the aforesaid with an iterative representation of a possible implementation. Although this algorithm is congruent with a code implementation, its worth noting that the input sequence can either have real or complex numbers, since the arithmetic is the same for both domains the only thing that needs to be specialized is the operator overloading in the inner most loop. \newline
\newline

% 3. Algorithmic overview
\SetKwComment{Comment}{/* }{ */}
\RestyleAlgo{ruled}
\begin{algorithm}[H]
    \caption{Radix-2 Decimation-in-Time Forward FFT} \label{alg:dit}
    \KwData{Sequence $in$ with size $N$ power of 2 }
    \KwResult{Sequence $out$ with size $N$ with the DFT of the input}

    \Comment{Bit reversal step}
    \ForEach{$i = 0$ \textbf{to} $N-1$}{
        $out[$bit\_reverse$(i)] \gets in[i]$
    }

    \Comment{FFT}
    \ForEach{$s = 1$ \textbf{to} $\log{N} $}{
        $m \gets 2^{s}$\;
        $w_{m} \gets \exp(-2\pi i / m)$\;
        \ForEach{$k = 0$ \textbf{to} $N-1$ \textbf{by} $m$}{
            $w \gets 1$\;
            \ForEach{$j = 0$ \textbf{to} $m/2$}{
                $bw \gets w \cdot out[k + j + m/2] $\;
                $a \gets out[k + j] $\;
                $out[k + j] \gets a + bw$\;
                $out[k + j + m/2] \gets a - bw$\;
                $w \gets w \cdot w_{m}$\;
            }
        }
    }
    \textbf{return} $out$\;
\end{algorithm}



\subsection{Radix-2 Decimation-in-Frequency FFT} \label{subsec:radix-2-dif} \label{subsec:radix-2-decimation-in-frequency-fft}

% 1. Explain the objective and what the DIF term means in the applied algorithm
The Radix-2 Decimation-in-Frequency FFT algorithm is very similar to the DIT approach, its based on the same principle of divide-and-conquer but it rearranges the original Discrete Fourier Transform (DFT) into the computation of two transforms, one with the even indexed elements and other with the odd indexed elements; as in this simplified formulation \autoref{eq:dif}.

\begin{equation} \label{eq:dif}
    \begin{aligned}
        X_{2k} &= \sum_{n=0}^{\frac{N}{2}-1} (x_{n} + x_{n + \frac{N}{2}}) \cdot \omega_{N/2}^{kn} \\
        X_{2k+1} &= \sum_{n=0}^{\frac{N}{2}-1} ((x_{n} - x_{n + \frac{N}{2}}) \cdot \omega_{N/2}^{kn}) \cdot \omega_{N}^{n} \\
    \end{aligned}
\end{equation}

\begin{equation*}
    \text{where } \omega_{N} = e^{\frac{i 2 \pi}{N}}
\end{equation*}

The DFT divided into these two transforms from the full sized DFT
By separating these two transforms from the full sized DFT we get two distinct 

Notably, this formulation distinguishes the full sized DFT into two \(N/2\) sized DFT's of the even and odd indexed elements where the later is multiplied by a twiddle factor \( \omega_{N}^{k} \) with both outside the same context. 
% \( X_{N} = E_{N/2} + W * O_{N/2} \)

This algorithm is a Radix-2 Decimation-in-Frequency since the DFT is deciminated into two distinct smaller DFT's and the frequency samples will be computed separately in different groups, as if the regrouping of the DFT's would reduce directly to the frequency domain. Since the understanding of this algorithm can be aplied recursively, the \autoref{fig:dif-fft} illustrates the this behaviour and represents the \(N/2\) subtransforms with boxes that can be filled by the recursive application of this algorithm to produce the frequency domain sequence. Aditionally this illustration can be compared to \autoref{fig:dit-fft} since both are symmetrically identical.

\begin{figure}[h] 
    \centering
    \includegraphics[width=0.5\textwidth]{imgs/dif_fft.png}
    \caption{Radix-2 Decimation-in-Frequency FFT \source{jones2014digital}}
    \label{fig:dif-fft}
\end{figure}

Similarly to the DIT version, the DFT can be recursively reduced by the DIF algorithm until theres only the computation of a length-2 DFT where its only applied the Gentleman-Sande butterfly operation \cite{chu1999inside} illustrated in \autoref{fig:dif-butterfly}.

% NOTE: Handmade since there wan't one that had exacly what i wanted
\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{imgs/dif_butterfly.png}
    \caption{Gentleman-Sande butterfly}
    \label{fig:dif-butterfly}
\end{figure}

Since this algorithm has similarities with the DIT, its complexity also lives to this similarity, maintaining the same \(O(N \log{N})\) for number of multiplications, despite that, \autoref{fig:dif-butterfly} and \autoref{fig:dit-butterfly} might look different in number of arithmetic operations since the first has 1 addition, 1 subtraction, and 2 multiplications, and the second has 1 addition, 1 subtraction, and 1 multiplication, but effectively the \(W_{N} \cdot b\) can be reused and only computed once as seen in \autoref{alg:dit}.
% FIXME: The complexity work within the algorithm is distributed with the DIT approach which decomposes each DFT by 2 having \(\log{N}\) stages \cite{smith2007mathematics} while there are approximately \(N\) complex multiplications needed for each stage of the DIT decomposition, therefore the multiplication complexity for a \(N\) sized DFT is reduced from \(O(N^{2})\) to \(O(N \log{N})\) without any programming specific optimizations.

As mentioned in \autoref{subsec:radix-2-decimation-in-time-fft} the bit reversal in DIF works a bit differently, this algorithm does the exact opposite of the DIT since it requires a natural order sequence and returns a bit reversed output, justifying why this step is applied after the algorithm.

% FIXME: im repeating exactly whats in the DIT but its exactly what i want to say, what to do? keep this or change?
In practice, \autoref{alg:dif} demonstrates the aforesaid with an iterative representation of a possible implementation. Although this algorithm is congruent with a code implementation, its worth noting that the input sequence can either have real or complex numbers, since the arithmetic is the same for both domains the only thing that needs to be specialized is the operator overloading in the inner most loop.

% 3. Algorithmic overview
\SetKwComment{Comment}{/* }{ */}
\RestyleAlgo{ruled}
\begin{algorithm}[H]
    \caption{Radix-2 Decimation-in-Frequency Forward FFT} \label{alg:dif}
    \KwData{Sequence $in$ with size $N$ power of 2 }
    \KwResult{Sequence $out$ with size $N$ with the DFT of the input}

    \Comment{FFT}
    \ForEach{$s = 0$ \textbf{to} $\log{N}-1 $}{
        $gs \gets N \gg s$\;
        $w_{gs} \gets \exp(2\pi i / gs)$\;
        \ForEach{$k = 0$ \textbf{to} $N-1$ \textbf{by} $gs$}{
            $w \gets 1$\;
            \ForEach{$j = 0$ \textbf{to} $gs/2$}{
                $a \gets in[k + j + gs/2] $\;
                $b \gets in[k + j] $\;
                $in[k + j] \gets a + b$\;
                $in[k + j + gs/2] \gets (a - b) \cdot w$\;
                $w \gets w \cdot w_{gs}$\;
            }
        }
    }
    
    \Comment{Bit reversal step}
    \ForEach{$i = 0$ \textbf{to} $N-1$}{
        $out[$bit\_reverse$(i)] \gets in[i]$
    }

    \textbf{return} $out$\;
\end{algorithm}



% % Algorithms side by side
% \begin{figure}[!ht]
%     \centering
%     \begin{subfigure}{.45\textwidth}
%         \centering
%         % Alg 1
%         \caption{Test Algorithm No.1}\label{alg:alg-1}
%     \end{subfigure}

%     \hfill

%     \begin{subfigure}{.45\textwidth}
%         \centering
%         % Alg 2
%         \caption{Test Algorithm No.2}\label{alg:alg-2}
%     \end{subfigure}
% \end{figure}


% \subsection{2D and 3D transforms}

% Altough we've already gonne through a lot of information ... its still unclear how these primitive functions on multidimentional targets, such as images.

% % TODO:
% Empty


% \section{Related Work}

% %TODO: 
% Empty

% \subsection{cuFFT}

% %TODO: 
% Empty

% \subsection{Fast Computation of general Fourier Transforms on GPUS}

% %TODO: 
% Empty
% Talk about that microsoft paper which implements efficiently in HLSL

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                     Algorithms analysis                      %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Algorithms analysis}


To flavour this pre-dissertation report some work of benchmarking and analysis were done to compete with the theoretical explanations addressed on \autoref{chap:state-of-the-art}. Hence, some implementations were tested to provide coherence to what has been studied, and algorithms such as \autoref{alg:dit} Radix-2 Decimantion-in-Time \autoref{alg:dif} Radix-2 Decimantion-in-Frequency were timed in \autoref{tab:benchmarking}.

\begin{table}[h]
    \centering
    \normalsize
    \sffamily
    \renewcommand{\arraystretch}{1.5}%
    \begin{tabular}{|c|l|l|l|l|l|}
        \hline
        \multicolumn{1}{|l|}{} & \multicolumn{1}{c|}{\textbf{Size 128}} & \multicolumn{1}{c|}{\textbf{Size 256}} & \multicolumn{1}{c|}{\textbf{Size 512}} & \multicolumn{1}{c|}{\textbf{Size 1024}} & \multicolumn{1}{c|}{\textbf{Size 2048}} \\ \hline
        \textbf{DFT}           & 5.16593                                & 17.2782                                & 70.5689                                & 293.104                                 & 1246.44                                 \\ \hline
        \textbf{FFT  DIT}      & 0.169113                               & 0.37668                                & 0.86415                                & 1.8793                                  & 4.47742                                 \\ \hline
        \textbf{FFT DIF}       & 0.159458                               & 0.378722                               & 0.881921                               & 1.90661                                 & 4.13369                                 \\ \hline
        \textbf{Recursive FFT} & 0.210895                               & 0.485643                               & 1.4421                                 & 2.32922                                 & 5.1178                                  \\ \hline
    \end{tabular}
    \caption{FFT algorithms benchmark. Results are \underline{measured in milliseconds} for forward and inverse computation with varying input sizes}
    \label{tab:benchmarking}
\end{table}

As we can see the Discrete Fourier Transform increases exponentially for higher sized sequences, as expected all FFT variants perform critically better than the original formulation.

One variant that wasn't exposed much in the above chapters is the Recursive FFT algorithm, which corresponds to a Decimation-in-Time aproach with recursive reduction, therefore this algorithm aggregates the divide-and-conquer method but with the disadvantage of recursive function overhead. This recursive look at the DIT approach can be easier to implement since the bit reversal step isn't explicitly applied before starting the FFT.

Finally, as expected the DIT and DIF algorithms overrule the other alternatives for every sized input.

% (DIT FFT) (DIF FFT) DFT
% (DIT FFT no bit reversal) (DIF FFT no bit reversal) DFT
% (FFT Recursive) DFT


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%             Computation of the Fourier Transform             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Computation of the Fourier Transform}


\section{Improving the Cooley-Tukey algorithm}
Nowadays there is a lot more to the computation of FFT's than just the basic Cooley-Tukey algorithm described in \ref{subsec:radix-2-decimation-in-time-fft} there are more algorithms, variations and improvements that enhace the computation in many aspects. Even the target hardware can change the restrictions on the computation of this primitive.

One could optimize the fft by providing precomputed twiddle factors, or spare space for the output sequence by adopting an inplace FFT algorithm  and all those factors influence the performance, evidently a balance must be stablished depending on the constraints for the FFT.

\subsection{Natural order Cooley-Tukey} \label{subsec:natural-order-ct}

TODO: Paste here the lost paragraph

Despite existing already really fast solutions for index bit reversal \cite{prado2004new}, this \textit{shufle} step still weights the algorithms with extra overhead. The natural order Cooley-Tukey FFT is a modification of the Cooley-Tukey algorithm that allows the removal of this step by computing the butterfly and reordering the elements per stage \cite{OTFFTnoct}.

\begin{figure}[h] 
    \centering
    \includegraphics[width=0.5\textwidth]{imgs/dif_elements_composition.png}
    \caption{Chain of even and odd compositions over each stage for a natural order DIF}
    \label{fig:dif-elements-composition}
\end{figure}
% Caption: Chain of compositions over each stage for a natural order DIF

At the end of each stage the even and odd elements are composed in such a way that the elements will be in natural order at the end. This composition follows the indexing scheme described in \autoref{eq:nat_order_even_indexing}.

% FIXME: Nao sei como ter isto tudo junto na mesma equacao
\begin{equation} \label{eq:nat_order_even_indexing}
    x[q + 2*p] = y[q + p] \\
\end{equation}
\begin{equation} \label{eq:nat_order_odd_indexing}
    x[q + 2*p + 1] = y[q + p + m] \\
\end{equation}

Where x and y are alternated sequences for read write over each stage, q corresponds to the sub fft offset in this stage, p is the index of the sub fft element shift for the current butterfly being computed, and finally the m corresponds to the size of the sub fft divided by 2.

Although this composition got rid of the bit reversal step in the Cooley-Tukey's algorithm, the performance is deprecated with more work for each stage. Work which may seem unecessary after we find out about the stockham algorithm that supersedes this algorithm.

% TODO: Rewrite better (maybe not very informative)
We can also note that the composition of even and odd elements wont be necessary on the last stage of the DIF FFT since it will be a passthrough of the elements, so this is an unnecessary step, however this algorithm is an intermediate step to make the stockham algorithm more rational so there's no need to worry about this detail.



\subsection{Stockham algorithm} \label{subsec:stockham-algorithm}

As mentioned on the former section, the Stockham algorithm comes to save us from the bit reversal step, it does this by taking advantage of a reordering of the elements \cite{govindaraju2008high} illustrated in \autoref{fig:dif-elements-composition}. The natural order elements are composed stage by stage and the butterfly computations stay the same, so this approach takes advantage of the Cooley-Tukey algorithm and turns it into a more suitable form for highly parallelizeable hardware such as GPUs, making it a best fit for our implementation in any GPU programmable language. \newline

Similarly to \autoref{subsec:natural-order-ct} the algorithm requires the usage alternated sequences for read write over each stage, this prevents the read of an element which has been altered before read in a given stage therefore the return sequence will depend on the $\log{N}$ number parity.

The stockham algorithm is described in \autoref{alg:stockham-dit} and this version may seem strictly different from the Cooley Tukey, specially the inner most loop, however most of the logic stays the same, the indexing is a bit different and simpler for this version and the if statements are a consequence of using alternated ping pong sequences since there has to be branches for read and write of both arrays for this out-of-place algorithm.
%it only affects the indexing of the elements

% TODO: Devo incluir a versão inversa? é que como so é preciso mudar um sinal nao acho que valha a pena e so fica mais verboso

% FIXME: O if statement tem um end antes do else nao sei como retirar

% 3. Algorithmic overview
\SetKwComment{Comment}{/* }{ */}
\RestyleAlgo{ruled}
\begin{algorithm}[H]
    \caption{Stockham Radix-2 Decimation-in-Time Forward FFT} \label{alg:stockham-dit}
    \KwData{Sequence pingpong0 with size $N$ power of 2}
    \KwResult{Sequence $out$ with size $N$ with the DFT of the input}

    \Comment{FFT}
    \ForEach{$s = 0$ \textbf{to} $\log{N}-1 $}{
        $gs \gets N \gg s$\;
        $stride \gets 1 \ll s$\;
        %$w_{gs} \gets \exp(2\pi i / gs)$\;
        \ForEach{$i = 0$ \textbf{to} $N-1$}{
            $p \gets i $ div $ stride $\;
            $q \gets i $ mod $ stride $\;
            $w_{p} = \exp(-2 \pi i / gs * p)$\;
            % HERE
            \If{$stage $ mod $ 2 == 0$}{
                $a \gets pingpong0[q + s*(p + 0)] $\;
                $b \gets pingpong0[q + s*(p + gs/2)] $\;
                \Comment{Perform butterfly}
                $pingpong1[q + s*(2*p + 0)] = a + b$\;
                $pingpong1[q + s*(2*p + 1)] = (a-b) * w_{p}$\;
            }
            \Else{
                $a \gets pingpong1[q + s*(p + 0)] $\;
                $b \gets pingpong1[q + s*(p + gs/2)] $\;
                \Comment{Perform butterfly}
                $pingpong0[q + s*(2*p + 0)] = a + b$\;
                $pingpong0[q + s*(2*p + 1)] = (a-b) * w_{p}$\;
            }
            %\EndIf
        }
    }
    \If{$\log{N} $ mod $ 2 == 0$}{
        \textbf{return} pingpong1\;
    }
    \Else{
        \textbf{return} pingpong0\;
    }
\end{algorithm}

\paragraph{}
Despite this algorithm description being an algorithmic or more close to a CPU implementation than GPU it will give us a solid structure to use as reference for our comparison subjects since it is feasible to make a similar implementation for GPGPU programmable languages due to the way of indexing and the usage of alternating sequences.

\subsection{Radix-4 instead of Radix-2}

Stepping forward on the need to optimize this algorithm we reach the topic of higher radix alternatives other than just radix-2, FFT algorithms can use higher radix for better performance and even mixed radix \cite{singleton1969algorithm} for more irregular sized input sequences.

The Radix-4 is a good improvement over Radix-2 since getting to higher radixes than 4 might result in reduced performance, so improving the Stockham algorithm with Radix-4 upgrades the computation of the butterflies while reducing the number of stages which will be crucial in later sections.

Theoretically Radix-4 formulation can be twice as fast as a Radix-2 \cite{hussain2010evaluation} since it only takes half the stages with a bit more complexity in the butterflies which are usually called dragonflies, and additionally can use less multiplications with better factorizations \cite{marti2009radix}.


% 1. 
\begin{figure}[h] 
    \centering
    \includegraphics[width=0.6\textwidth]{tese/imgs/dragonfly.png}
    \caption{Radix-4 FFT butterfly structure \source{marti2009radix}}
    \label{fig:radix4-dragonfly}
\end{figure}


TODO: WIP

\SetKwComment{Comment}{/* }{ */}
\RestyleAlgo{ruled}
\begin{algorithm}[H]
    \caption{Stockham Radix-2 Decimation-in-Time Forward FFT} \label{alg:stockham-dit}
    \KwData{Sequence pingpong0 with size $N$ power of 2}
    \KwResult{Sequence $out$ with size $N$ with the DFT of the input}

    \Comment{FFT}
    \ForEach{$s = 0$ \textbf{to} $\log{N}-1 $}{
        $gs \gets N \gg s$\;
        $stride \gets 1 \ll s$\;
        %$w_{gs} \gets \exp(2\pi i / gs)$\;
        \ForEach{$i = 0$ \textbf{to} $N-1$}{
            $p \gets i $ div $ stride $\;
            $q \gets i $ mod $ stride $\;
            $w_{p} = \exp(-2 \pi i / gs * p)$\;
            % HERE
            \If{$stage $ mod $ 2 == 0$}{
                $a \gets pingpong0[q + s*(p + 0)] $\;
                $b \gets pingpong0[q + s*(p + half_gs)] $\;
                \Comment{Perform butterfly}
                $pingpong1[q + s*(2*p + 0)] = a + b$\;
                $pingpong1[q + s*(2*p + 1)] = (a-b) * w_{p}$\;
            }
            \Else{
                $a \gets pingpong1[q + s*(p + 0)] $\;
                $b \gets pingpong1[q + s*(p + gs/2)] $\;
                \Comment{Perform butterfly}
                $pingpong0[q + s*(2*p + 0)] = a + b$\;
                $pingpong0[q + s*(2*p + 1)] = (a-b) * w_{p}$\;
            }
            %\EndIf
        }
    }
    \If{$\log{N} $ mod $ 2 == 0$}{
        \textbf{return} pingpong1\;
    }
    \Else{
        \textbf{return} pingpong0\;
    }
\end{algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                  Implementation on the GPU                   %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Implementation on the GPU}

To be able to analyse the implementation of FFT on the GPU, we need to provide some background on what kind of hardware were dealing with, whats constraints are relevant and what we can or can't do, after, we proceed with with description of how the Fourier Transform suits the GPU programming model and finally we'll move forward to a detailed analysis of the implementation of FFT algorithms in a compute shader in GLSL.

\section{GPU Programming model}

% Introducing GPU and why it is better
% GPU architecture and programming model
% What we can do and how to take advantage of the GPU
% Compute pipeline in GLSL

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% TODO: Rewrite this phrase
The Graphics Processing Unit (GPU) provides much higher instruction throughput and memory bandwidth than the CPU within a similar price and power envelope having a much faster performance growth curve. Many applications leverage these higher capabilities to run faster on the GPU than on the CPU. While the hardware may change some components and architecture on different models, fundamentally most modern GPUs adopt a specific kind of single instruction multiple data (SIMD) stream architecture which is single instruction multiple threads (SIMT) that is an extension of the SIMD paradigm with large scale multi-threading, streaming memory and dynamic scheduling. \newline

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
A SIMT stream architecture forwards an instruction to multiple threads with dedicated memory for each instance, allowing data-level parallelism to compute more quickly and effectively.
A modern CPU uses a von Neumann architecture, so it executes instructions sequentially one at a time and updates the memory progressively, however a stream architecture processor works in a slightly different way, they contain multiple streams of simpler processors with shared memory just like the illustration in \autoref{fig:cpu-gpu}. These processors execute programs called kernels that receive a finite set of input fragments to produce another set of output fragments in parallel \cite{fernando2004gpu}. \newline

With the introduction of programmable General Purpose Graphics Processing Unit (GPGPU) the industry required a lot more parallel algorithms.

%This paradigm revolutionised the industry and with its evolution came the General Purpose Graphics Processing Unit (GPGPU) which allows this type of hardware to compute highly parallel procedures similarly to a CPU but with all the advantages of a GPU. \newline

%Nowadays most GPUs provide this general purpose programming functionality and many parallel computing platforms help us take advantage of that such as Nvidia’s CUDA, OpenCL, or even graphics APIs like OpenGL with compute shaders. These tools help abstract the hardware and provide facilities to allow developers to focus on higher-level computing procedures.

platforms allow developers to ignore the language barrier that exists between the CPU and the GPU and, instead, focus on higher-level computing concepts.

% TODO: Cite the source
\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{imgs/cpu_gpu.png}
    \caption{CPU architecture compared with a GPU architecture}
    \label{fig:cpu-gpu}
\end{figure}

% FIXME: NOT SURE IF 'attend' HAS THE CORRECT MEANING IN THIS SENTENCE
Developers and researchers often attend more specific scenarios and they configure multiple GPUs with distributed workflows in sync with each other to take better advantage of this hardware for more intensive problems \cite{heldens2022lightning}.

The GPU programming model although sophisticated, at its core it provides thread groups hierarchies, shared memories and GPU barriers for synchronisation of threads, such abstractions provide data and thread level parallelism for the developer to ulitize. \newline

%%%%%
In this programming model we introduce the concept of granularity, that refers to the amount of computation relatively to the transfer of data. It is used to describe types of parallelism as fine-grained or coarse-grained. 
Fine-grained parallelism describes a small multi threaded tasks in kernel size and execution time with frequent small data transfers between the processors. On the opposite side there's coarse-grained parallelism that describes larger amounts of computation followed by larger infrequent data transfers \cite{CUDAcppguide}.

% SUMMARY OF: % In parallel programming, granularity means the amount of computation in relation to communication (or transfer) of data. Fine-grained parallelism means individual tasks are relatively small in terms of code size and execution time. The data is transferred among processors frequently in amounts of one or a few memory words. Coarse-grained is the opposite in that data is communicated infrequently, after larger amounts of computation.
%%%%%%

This concept is important to reflect on the association of the GPU programming model with further details on the provided implementations within the next chapters. \newline

%%%%%
Most GPGPU programming frameworks such as CUDA provide coarse-grained data and task parallelism with nested fine-grained data and thread parallelism. This type of task hierarchy architecture promotes the partitioning of the problems to independently solvable subgroups of smaller problems which fit into smaller blocks of threads that can be solved cooperatively in parallel. This relevant information provides us more insight of how the work groups for FFT should be dispatched.
% SUMMARY OF: % The CUDA abstractions provide fine-grained data parallelism and thread parallelism, nested within coarse-grained data parallelism and task parallelism. They guide the programmer to partition the problem into coarse sub-problems that can be solved independently in parallel by blocks of threads, and each sub-problem into finer pieces that can be solved cooperatively in parallel by all threads within the block.
%%%%%


% NOTE - Cant sync in between local threads of the same thread group, only sync with work groups (Say thgis here, and then on the chapter of the explanation of the implementation on the GPU)

% [x] Talk about the programming model, the concepts of a warp/Work groups and threads/local groups
% What we can do and how to take advantage of the GPU



\section{2D Fourier Transform on the GPU}
% - 2D FFT's 
%   - Greyscale images
%   - RGB to Complex domain (relative luminance)
%   - 2D FFT formula representation
% - Two pass approach for Horizontal and Vetical passes


% FIXME: Soft text, needs a more formal rewrtite
% Reference page 4 
Computing a 2D Fourier Transform requires a two dimensional input sequence to produce another for the output. However we could use any usable arbitrary values in the the real world we often use this 2D FFT on images and it isn't immediately obvious how this should be applied since the target data source might have three color channels, therefore three different values for this multidimensional sequence element that can be used, and not even in floating point complex domain. Precisely, it needs to be adapted to the application use case, we may use it as greyscale image if want a derivation of the luminance via quantized RGB signals of the image \citep{itu2002parameter}, use only the values of one channel, or compute multiple FFT's for each channel values. Either way we will preferably at the end have a two dimensional buffer with floating point complex values prepared to be used.
\newline


% USED %\cite{dudgeon1984multidimensional} % for horizontal and vertical passes
The 2D FFT is computed by performing single dimension FFT's for every row and then for every columns after that \cite{dudgeon1984multidimensional}, so we can divide its application to a horizontal and vertical pass. This describes the way 2D FFT are computed but it is independent of the 1D FFT implementation chosen, so there's freedom to use any type of algorithm.

% TODO: Formula
% \cite{mermer2003efficient} % FOR THE FORMULA

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{tese/imgs/2d_fft.png}
    \caption{High level illustration of horizontal and vertical passes}
    \label{fig:2d-fft}
\end{figure}

At the end of a forward FFT vertical pass the result will be a 2D complex buffer with the frequency domain values of the original image as illustrated in \autoref{fig:2d-fft}.


\section{Implementation Analysis in GLSL}

The implementations were made using GLSL, a high-level shader language for graphics API's such as OpenGL, and it was used the compute pipeline from OpenGL to integrate a FFT implementation using compute shaders, which are general purpose programmable shaders.

Since there are many aspects that may impact on the performance the implementation was an interactive process that required researching and testing to compose an optimal solution. One of the main targets was to keep the code generalised so that it can be used as base for other implementations using FFTs.
\newline

The next sections go in detail about the way every major iteration evolved into the next one and why there was the need to do it, starting by the Cooley-Tukey algorithm then progressively improving on the Stockham algorithm, all this while implementing good GPGPU programming strategies.

% - [x] Brief about GLSL and the compute shaders used
% - [x]  Compute pipeline in GLSL
% - [x] Say it was an iterative process by applying, studying and testing

\subsection{Cooley-Tukey}

% Basic algorithm
% - iterative version
% - based on the dit described in state of art
% -

%FIXME: The beginning of this phrase is weird, rewrite
The GPU implementation took as a starting point was with the DIT Cooley-Tukey algorithm, since it is the most popular one with time complexity of $O(N\log{N})$, and it is based on the iterative version adapted for parallel processors.

Since this implementation is highly parallel there's the need to separate the reads and writes for each processor into two different buffers in memory due lack of order between processors, therefore the declaration of two complex pingpong buffers.

\begin{lstlisting}[language=C]
 layout (binding = 0, rg32f) uniform image2D pingpong0;
 layout (binding = 1, rg32f) uniform image2D pingpong1;
\end{lstlisting}

The read write control for this buffers can be achieved with a flag variable \texttt{pingpong}.

Initially this algorithm will work with a pass per stage approach, where a kernel is dispatched every stage and since there's a synchronisation step at the end of the pass its granted that all the work groups have finished off writing to the buffer when a pass ends. This case holds up for both the horizontal and vertical FFT steps.

As a result, each kernel has the opportunity to work within every segment of the image, so the local threads can be dispatched with two dimensions, so each work group will have a total of 32 local threads, a reference number used in this implementations for setting up local threads in a work group, this may vary depending on the GPU for optimal performance but 32 is a good number to fill in the thread warp size os most GPUs.

So an example dispatch group for this implementation could be $(fft\_width/8,fft\_height/8)$ work groups since 8 is the number of threads in the $y$ axis

By using GLSL there is some advantages on the complex values operations, since the addition and subtraction for vector types already have operators overloading which function the same as in the complex domain. However the multiplication works a bit differently so we need to provide an auxiliary function to abstract and support this operator.

\begin{lstlisting}[language=C,caption=Complex multiplication]
 vec2 complex_mult(vec2 v0, vec2 v1) {
 	return vec2(v0.x * v1.x - v0.y * v1.y,
 				v0.x * v1.y + v0.y * v1.x);
 }
\end{lstlisting}

Due to the adoption of a different programming paradigm the FFT segment iteration loop doesn't exist such as in \autoref{alg:dit}, instead the processors identifiers are used to fetch the index of the butterflies they're gonna work on based on the work groups and threads dispatch setup, and this holds up for any implementation using compute shaders.

\begin{lstlisting}[language=C]
 int line = int(gl_GlobalInvocationID.x);
 int column = int(gl_GlobalInvocationID.y);
\end{lstlisting}

Since this first approach is a dynamic implementation that invokes a pass per stage some stage control variables need to be feed into the shader in order to compute the correct butterfly index or control the butterfly process.

\begin{lstlisting}[language=C]
 uniform int pingpong;
 uniform int log_width;
 uniform int stage;
 uniform int fft_dir;
\end{lstlisting}

Effectively, we use these shader uniform input variables and obtain actual index we're gonna use on the 1D FFT of the image.

\begin{lstlisting}[language=C]
 int group_size = 2 << stage;
 int shift = 1 << stage;
 
 int idx = (line % shift) + group_size * (line / shift);
\end{lstlisting}

To calculate the twiddle factor we use Euler's formula such as in \autoref{eq:euler} and resort to the control variable \texttt{fft\_dir} to flip the twiddle factor for the inverse if we want to reuse this shader.

\begin{lstlisting}[language=C]
 vec2 euler(float angle) {
     return vec2(cos(angle), sin(angle));
 }
 
 void main() {
     // ...
     vec2 w = euler(fft_dir * 2 * (M_PI / group_size) * ((idx % group_size) % shift));
     // ...
 }
\end{lstlisting}

% Explain butterfly
% - butterfly alternate read writes
Now with the computed twiddle factor we may proceed to compute and store the Cooley-Tukey FFT butterfly, and that's where we need to control the reads and writes for each stage. Since the \texttt{pingpong} variable is toggled every pass invocation, it is used to choose with what image we will use to lookup the elements and which one to store into, and that is achieved with an if statement, just like it is used in \autoref{alg:stockham-dit}.

The butterfly computation itself is simply calculated as a Cooley-Tukey DIT butterfly as illustrated in \autoref{fig:dit-butterfly}.

\begin{lstlisting}[language=C]
 if (pingpong == 0) {
     // Read
     a = imageLoad(pingpong0, ivec2(idx, column)).rg;
     b = imageLoad(pingpong0, ivec2(idx + shift, column)).rg;

     // Compute and store
     vec2 raux = a + complex_mult(w, b);
     imageStore(pingpong1, ivec2(idx, column), vec4(raux, 0, 0));
     raux = a - complex_mult(w, b);
     imageStore(pingpong1, ivec2(idx + shift, column), vec4(raux, 0, 0));
 }
 else {
     // Read
     a = imageLoad(pingpong1, ivec2(idx, column)).rg;
     b = imageLoad(pingpong1, ivec2(idx + shift, column)).rg;
     
     // Compute and store
     vec2 raux = a + complex_mult(w, b);
     imageStore(pingpong0, ivec2(idx, column), vec4(raux,0,0));    
     raux = a - complex_mult(w, b);
     imageStore(pingpong0, ivec2(idx + shift, column), vec4(raux,0,0));
 }
\end{lstlisting}

Finally there's only one step missing, the bit reversal of indices to have a natural order result. A \texttt{bit\_reverse} function could be easily defined, however there's already a GLSL alternative which is \texttt{bitfieldReverse} together with \texttt{bitfieldExtract} \cite{kessenich4opengl}.

Despite not having a noticeable performance hit, it is good practice to use GLSL predefined functions and operators since they might be optimised for that specific device hardware and using these functions instead of a handmade implementation reduces the kernel size significantly about approximately 400 bytes (evaluated using \textit{glslang}) since they are reusable functions. 

\begin{lstlisting}[language=C]
 int bit_reverse(int k) {
     uint br = bitfieldReverse(k);
     return int(bitfieldExtract(br, 32 - log_width, log_width));
 }
\end{lstlisting}

% - butterfly initial bit reverse on first stage
This auxiliar function will be conditionally used inside the branching if statement for alternating read writes to be only applied on the first stage of transform both for the possible values of \texttt{pingpong == 0} and \texttt{pingpong == 1}, since the vertical pass might start reading on the first pingpong buffer. This is not the case for the horizontal pass, its ensured that the first stage will always read from \texttt{pingpong0} reforccing that the bit reverse branching when \texttt{pingpong == 0} is disposable.

\begin{lstlisting}[language=C]
 if (pingpong == 0) {
     if (stage == 0) {
         a = imageLoad(pingpong0, ivec2(bit_reverse(idx), column)).rg;
         b = imageLoad(pingpong0, ivec2(bit_reverse(idx + shift), column)).rg;
     }
     else {
         a = imageLoad(pingpong0, ivec2(idx, column)).rg;
         b = imageLoad(pingpong0, ivec2(idx + shift, column)).rg;
     }

     // ... Compute and store results
 }
 else {
     a = imageLoad(pingpong1, ivec2(idx, column)).rg;
     b = imageLoad(pingpong1, ivec2(idx + shift, column)).rg;

     // ... Compute and store results
 }
\end{lstlisting}

%We can already see some branching in this code that might not be desirable.
% Cooley-Tukey

% Initial implementation model
% - [x]Read write requirements
% - [x] Per stage synchronisation (multiple submissions)
% - [ ] 2D Work dispatch (with illustration)

% - [x] Vector type operations
% - [x] Mention to use GLSL bitreverse instead of manual implementation (perhaps no noticeable performance but the kernel size reduces significantly)
% - pass per stage
%     - The way it is dispatched and why it is made that way
% - Updating to all stages in a single pass
%     - One problem of this is the synchronization between threads
%     - And by using only 1 pass for all stages there's a big difference, the implementation can be static for the size, so there's no branching associated, with that the pingpong variable now is constexpr so the compiler optimizes the kernel execution to inline the ifstatement and the while loop
% - Reference somewhere with loop unroll glsl version



% AT THE END OF THIS TOPIC MAKE A DIAGRAM WITH 2 REPRESEWNTATIONS OF THE PASSES EXECUTION AND THE INTEMEDIATE STEPS OF LUA SCRIPTS AND HOW MUCH SYNCHRONIZATION OVERHEAD THERE IS.

With all this steps aggregated, the shader for the horizontal pass of this FFT DIT Cooley-Tukey implementation will be such as \autoref{lst:ct-horizontal}.

\begin{lstlisting}[language=C,caption={FFT Cooley-Tukey Horizontal},label={lst:ct-horizontal}]
 #version 440
 
 #define M_PI 3.1415926535897932384626433832795
 
 layout (local_size_x = 4, local_size_y = 8) in;
 
 layout (binding = 0, rg32f) uniform image2D pingpong0;
 layout (binding = 0, rg32f) uniform image2D pingpong1;
 
 uniform int pingpong;
 uniform int log_width;
 uniform int stage;
 uniform int fft_dir;
 
 vec2 complex_mult(vec2 v0, vec2 v1) {
 	return vec2(v0.x * v1.x - v0.y * v1.y,
 				v0.x * v1.y + v0.y * v1.x);
 }
 
 int bit_reverse(int k) {
     uint br = bitfieldReverse(k);
     return int(bitfieldExtract(br, 32 - log_width, log_width));
 }
 
 vec2 euler(float angle) {
 	return vec2(cos(angle), sin(angle));
 }
 
 void main() {
 	int line = int(gl_GlobalInvocationID.x);
 	int column = int(gl_GlobalInvocationID.y);
 
 	int group_size = 2 << stage;
 	int shift = 1 << stage;
 
 	vec2 a, b;
 
     int idx = (line % shift) + group_size * (line / shift);
     vec2 w = euler(fft_dir * 2 * (M_PI / group_size) * ((idx % group_size) % shift));
 
     if (pingpong == 0) {
         if (stage == 0) {
             a = imageLoad(pingpong0, ivec2(bit_reverse(idx), column)).rg;
             b = imageLoad(pingpong0, ivec2(bit_reverse(idx + shift), column)).rg;
         }
         else {
             a = imageLoad(pingpong0, ivec2(idx, column)).rg;
             b = imageLoad(pingpong0, ivec2(idx + shift, column)).rg;
         }
 
         vec2 raux = a + complex_mult(w, b);
         imageStore(pingpong1, ivec2(idx, column), vec4(raux, 0, 0));
             
         raux = a - complex_mult(w, b);
         imageStore(pingpong1, ivec2(idx + shift, column), vec4(raux, 0, 0));
     }
     else {
         a = imageLoad(pingpong1, ivec2(idx, column)).rg;
         b = imageLoad(pingpong1, ivec2(idx + shift, column)).rg;
 
         vec2 raux = a + complex_mult(w, b);
         imageStore(pingpong0, ivec2(idx, column), vec4(raux,0,0));
             
         raux = a - complex_mult(w, b);
         imageStore(pingpong0, ivec2(idx + shift, column), vec4(raux,0,0));
     }
 }
\end{lstlisting}

% TODO: Mention this normalization in the 2D
For the vertical pass shader there is however one extra multiplication by \texttt{mult\_factor} in the butterfly results for the last stage when the pass is inverse. This corresponds to the normalization of the multidimensional transform simlilar to the normalization in the inverse DFT in \autoref{eq4}.

\begin{lstlisting}[language=C,caption={FFT Cooley-Tukey Vertical},label={lst:ct-vertical}]
#version 440

#define M_PI 3.1415926535897932384626433832795

layout (local_size_x = 8, local_size_y = 4) in;

layout (binding = 0, rg32f) uniform image2D pingpong0;
layout (binding = 1, rg32f) uniform image2D pingpong1;

uniform int pingpong;
uniform int log_width;
uniform int stage;
uniform int fft_dir;

int iter = 1 << log_width;
int shift = (1 << stage);

vec2 complex_mult(vec2 v0, vec2 v1) {
	return vec2(v0.x * v1.x - v0.y * v1.y,
				v0.x * v1.y + v0.y * v1.x);
}

int bit_reverse(int k) {
    uint br = bitfieldReverse(k);
    return int(bitfieldExtract(br, 32 - log_width, log_width));
}

vec2 euler(float angle) {
	return vec2(cos(angle), sin(angle));
}

void main() {
	int line = int(gl_GlobalInvocationID.x);
	int column = int(gl_GlobalInvocationID.y);

	int group_size = 2 << stage;
	int shift = 1 << stage;

	vec2 a, b;

    int idx = (column % shift) + group_size * (column / shift);
    vec2 w = euler(fft_dir * 2 * (M_PI / group_size) * ((idx % group_size) % shift));

    float mult_factor = 1.0;
    if ((stage == log_width - 1) && fft_dir == 1) {
        mult_factor = 1.0 / (iter*iter) ;
    }

    if (pingpong == 0) {
        if (stage == 0) {
            a = imageLoad(pingpong0, ivec2(line, bit_reverse(idx))).rg;
            b = imageLoad(pingpong0, ivec2(line, bit_reverse(idx + shift))).rg;
        }
        else {
            a = imageLoad(pingpong0, ivec2(line, idx)).rg;
            b = imageLoad(pingpong0, ivec2(line, idx + shift)).rg;
        }
        
        vec2 raux = (a + complex_mult(w, b)) * mult_factor;
        imageStore(pingpong1, ivec2(line, idx), vec4(raux,0,0));
            
        raux = (a - complex_mult(w, b)) * mult_factor;
        imageStore(pingpong1, ivec2(line, idx + shift), vec4(raux,0,0));
    }
    else {
        if (stage == 0) {
            a = imageLoad(pingpong1, ivec2(line, bit_reverse(idx))).rg;
            b = imageLoad(pingpong1, ivec2(line, bit_reverse(idx + shift))).rg;
        }
        else {	
            a = imageLoad(pingpong1, ivec2(line, idx)).rg;
            b = imageLoad(pingpong1, ivec2(line, idx + shift)).rg;
        }

        vec2 raux = (a + complex_mult(w, b)) * mult_factor;
        imageStore(pingpong0, ivec2(line, idx), vec4(raux,0,0));
            
        raux = (a - complex_mult(w, b)) * mult_factor;
        imageStore(pingpong0, ivec2(line, idx + shift), vec4(raux,0,0));
    }
}
\end{lstlisting}

We can already see in the above code a lot of branching that might be undesirable on the GPU  ... % TODO: Reference that thing where a warp branching has a huge performance hit due to the way it is implemented

\subsubsection{All stages in one pass}

The previous implementation demonstrates a generic 2D FFT that may be reused for multiple FFT sizes, however this comes at a cost of efficiency when it comes to the synchronisation of the of the stage itself, moreover it requires use multiple uniform variables for control of the FFT that are transferred between CPU and GPU when there are updates in between stages.
\newline

% NOTE: Uncertain if the 'kernel-wise' is a good way to say
Undoubtedly the best solution here is to port this implementation synchronisation step to be kernel-wise and this detail changes quite a bit the properties of how the code is structured and how it may be dispatched.

At the moment there isn't a way to trivially ensure the reads and writes of all work groups  \cite{stuart2011efficient} without interrupting at the end of the stage, but there is functions that make use of barriers that synchronise all the threads within a work group. However there is a lot of literature on behalf of GPU compute execution synchronisation (maybe list some references here) we'll make use of the GLSL predefined barrier synchronisation functions.

The current grouping of threads doesn't allow the use of these barrier synchronisation since the computation of one dimensional FFT is distributed between multiple work groups, so using a call to \texttt{barrier()} inside the kernel wouldn't fix the race conditions of several segments of the image. We could however, change the setup of these work groups in such way that each 1D FFT threads fit in one work group. 

% Updating to all stages in a single pass %
% - One problem of the previous is the synchronisation between threads and multiple input variables for control that update on the cpu.
% - For this we need to sync inside fft and we dont have a way to arbitrarly sync between work groups but we can sync between local threads
% - Dispatch settings may be changed to allow an implementation to sync the stage between reads and writes for each one dimensional FFT
% ====================================== %
%   - Image that represents the before and after of the dispatch architecture
% - Pros and const of this way of dispatching work groups
%   - Cons: there is less immediate control over how many threads we want in each work group since we need as many as FFT_SIZE / 2.

% - And by using only 1 pass for all stages there's a big difference, the implementation can be static for the size, so there's no branching associated, with that the pingpong variable now is constexpr so the compiler optimizes the kernel execution to inline the ifstatement and the while loop
% - Reference somewhere with loop unroll glsl version

\subsection{Radix-2 Stockham}

\subsection{Radix-4 Stockham}
% - We may use simple multiplication arithmethic to flip the operator according to the fft direction
% - Explain what is branchless programming and how it may affect the code and how it may not affect this code
% - Loop inlines and stripped down if statements on const expressions
% - Information  obtained directly from compiling source code with a sahder compiler to intermediate representation
% - Any shader compiler strips down every piece of the kernel and tries to apply optimizations to most operations 
% TODO: Testing inlined loop vs the code provided



% - Matrix transposition mention, and that the results aren't better

\section{Case of study}
\subsection{Tensendorf waves}

% Say "An application use case that relies heavily on FFT's to deliver fast performance"

\subsection{Implementation details}
\subsection{Results}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                   Analysis and Comparison                    %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Analysis and Comparison}
\section{Popular implementations}
\subsection{cuFFT}
\subsection{FFTW}
\section{Comparison with GLSL implementation}
\subsection{Results}
% - Add GPU, CPU, graphics drivers operating system and graphics video memory for reference of the data collected
% - Benchmark on another nvidia gpu laptop and collect the data to check for the analysis coherency on multiple gpu's
Popular implementations

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                     END OF MAIN CHAPTERS                     %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bookmarksetup{startatroot} % Ends last part.
% \addtocontents{toc}{\bigskip} % Making the table of contents look good.
\cleardoublepage

% Bibliography (requires 'bibtex'  package)
\addcontentsline{toc}{chapter}{Bibliography}
\bibliographystyle{acm}
\bibliography{dissertation}
% Index of terms (required 'makeindex' package)
\printindex

    
    \appendix
    \renewcommand\chaptername{Appendix}

    % Add appendix chapters

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \part{Appendices}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \chapter{Support work}
% 	Auxiliary results which are not main-stream

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \chapter{Details of results}
%          Details of results whose length would compromise readability of main text.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \chapter{Listings}
% 	Should this be the case

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \chapter{Tooling}
% 	(Should this be the case)

% 	Anyone using \Latex\ should consider having a look at \TUG,
% 	the \tug{\TeX\ Users Group}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \begin{backcover}
% \thispagestyle{empty} \pagecolor{white} \textcolor{black} {\fontfamily{phv}\fontseries{mc}\selectfont ~\vfill
% \noindent
% NB: place here information about funding, FCT project, etc in which the work is framed. Leave empty otherwise.
% %
% \vfill ~}
% \end{backcover}

\end{document}
